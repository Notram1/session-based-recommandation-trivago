{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c2878070199e72c2f7201be8ea80bcf2840fc9aff010b343dcec2dca885b35f6",
   "display_name": "Python 3.7.10 64-bit ('trivago': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from data import *\n",
    "from utils import *\n",
    "from constant import *\n",
    "from nn import *\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUDA_VISIBLE_DEVICES:  0\n",
      "{'alias': 'NN', 'batch_size': 128, 'categorical_emb_dim': 128, 'debug': True, 'device_id': 0, 'dropout_rate': 0, 'early_stopping': 1, 'hidden_dims': [256, 128], 'learning_rate': 0.001, 'loss': \"<class 'torch.nn.modules.loss.BCELoss'>\", 'num_embeddings': {}, 'num_epochs': 1, 'optimizer': 'adam', 'sequence_length': 10, 'sess_length': 30, 'slack': True, 'sub_sample': False, 'use_cuda': True, 'use_test': True, 'verbose': True, 'weight_decay': 0}\n",
      "93it [00:00, 653.30it/s]\n",
      "5it [00:00, 829.93it/s]\n",
      "135it [00:00, 962.36it/s]\n",
      "explained ratio 0.652722579943809\n",
      "explained ratio 0.7836684017482803\n",
      "Number of training data: (3683, 142)\n",
      "Number of validation data: (125, 142)\n",
      "Number of test data: (1497, 142)\n",
      "{'alias': 'NN', 'all_cat_columns': ['user_id', 'item_id', 'city', 'action', 'city_platform', 'price_rank', 'impression_index', 'star'], 'batch_size': 128, 'categorical_emb_dim': 128, 'continuous_size': 119, 'debug': True, 'device_id': 0, 'dropout_rate': 0, 'early_stopping': 1, 'hidden_dims': [256, 128], 'learning_rate': 0.001, 'loss': \"<class 'torch.nn.modules.loss.BCELoss'>\", 'neighbor_size': 5, 'num_embeddings': {'user_id': 1976, 'item_id': 6568, 'city': 915, 'action': 44, 'city_platform': 1258, 'price_rank': 25, 'impression_index': 26, 'star': 6}, 'num_epochs': 1, 'optimizer': 'adam', 'sequence_length': 10, 'sess_length': 30, 'slack': True, 'sub_sample': False, 'target_action': 'clickout item', 'transformed_clickout_action': 2, 'transformed_dummy_action': 43, 'transformed_dummy_item': 6567, 'transformed_nan_item': 5910, 'use_cuda': True, 'use_test': True, 'verbose': True, 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nn_xnn_time_diff_v2'\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed_everything(42)\n",
    "\n",
    "configuration = NNConfiguration()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(configuration.device_id)\n",
    "print(\"CUDA_VISIBLE_DEVICES: \", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "if configuration.sub_sample:\n",
    "    model_name += '_140k'\n",
    "else:\n",
    "    model_name += '_all'\n",
    "\n",
    "if configuration.use_test:\n",
    "    model_name += '_ut'\n",
    "\n",
    "if configuration.debug:\n",
    "    model_name += '_db'\n",
    "\n",
    "model_name += f'_{configuration.device_id}'\n",
    "\n",
    "weight_path = f\"../weights/{model_name}.model\"\n",
    "\n",
    "print(configuration.get_attributes())\n",
    "\n",
    "data_gen = NNDataGenerator(configuration)\n",
    "\n",
    "print(configuration.get_attributes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (emb_dict): ModuleDict(\n    (user_id): Embedding(1976, 128)\n    (item_id): Embedding(6568, 128, padding_idx=6567)\n    (city): Embedding(915, 128)\n    (action): Embedding(44, 128)\n    (city_platform): Embedding(1258, 128)\n    (price_rank): Embedding(25, 128)\n    (impression_index): Embedding(26, 128)\n    (star): Embedding(6, 128)\n  )\n  (gru_sess): GRU(256, 64, num_layers=2, batch_first=True, bidirectional=True)\n  (other_item_gru): GRU(128, 64, batch_first=True, bidirectional=True)\n  (cont_linear): Linear(in_features=119, out_features=128, bias=True)\n  (hidden1): Linear(in_features=2176, out_features=256, bias=True)\n  (hidden2): Linear(in_features=502, out_features=128, bias=True)\n  (output): Linear(in_features=128, out_features=1, bias=True)\n  (bn): BatchNorm1d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (bn_hidden): BatchNorm1d(502, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)\n"
     ]
    }
   ],
   "source": [
    "valid_data = data_gen.val_data\n",
    "train_data= data_gen.train_data\n",
    "\n",
    "if configuration.use_cuda:\n",
    "    net = Net(configuration).cuda()\n",
    "else:\n",
    "    net = Net(configuration)\n",
    "\n",
    "optim = use_optimizer(net, configuration)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min',min_lr=0.0005, factor=0.7, verbose=True)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(loader, net):\n",
    "    net.eval()\n",
    "    all_scores = []\n",
    "    validation_loss = []\n",
    "    for batch_id, data in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            item_ids = Variable(data[0]).to(device=device_type)\n",
    "            targets = Variable(data[1]).to(device=device_type)\n",
    "            past_interactions = Variable(data[2]).to(device=device_type)\n",
    "\n",
    "            past_interaction_masks = (data[3])\n",
    "\n",
    "            price_rank = Variable(data[4]).to(device=device_type)\n",
    "            city = Variable(data[5]).to(device=device_type)\n",
    "            last_item =  Variable(data[6]).to(device=device_type)\n",
    "            impression_index = Variable(data[7]).to(device=device_type)\n",
    "            continuous_features = Variable(data[8]).to(device=device_type)\n",
    "\n",
    "            star = Variable(data[9]).to(device=device_type)\n",
    "            \n",
    "            past_interactions_sess = Variable(data[10]).to(device=device_type)\n",
    "            past_actions_sess = Variable(data[11]).to(device=device_type)\n",
    "\n",
    "            \n",
    "            last_click_item = Variable(data[12]).to(device=device_type)\n",
    "            last_click_impression = Variable(data[13]).to(device=device_type)\n",
    "            last_interact_index = Variable(data[14]).to(device=device_type)\n",
    "            neighbor_prices = Variable(data[15]).to(device=device_type)\n",
    "            other_item_ids = Variable(data[16]).to(device=device_type)\n",
    "            city_platform = Variable(data[17]).to(device=device_type)\n",
    "\n",
    "            prediction = net(item_ids, past_interactions, past_interaction_masks, price_rank, city, last_item, impression_index, continuous_features, star, past_interactions_sess, past_actions_sess, last_click_item, last_click_impression, last_interact_index, neighbor_prices, other_item_ids, city_platform)\n",
    "            loss = crit(prediction,targets).item()\n",
    "            prediction = prediction.detach().cpu().numpy().tolist()\n",
    "            all_scores += prediction\n",
    "            validation_loss.append(loss)\n",
    "    validation_loss = np.mean(validation_loss)\n",
    "    return all_scores, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_valid(val_loader, val_df, net ):\n",
    "    \n",
    "            \n",
    "    val_df['score'], val_loss = get_prediction(val_loader, net)\n",
    "\n",
    "    \n",
    "    grouped_val = val_df.groupby('session_id')\n",
    "    rss = []\n",
    "    rss_group = {i:[] for i in range(1,26)}\n",
    "    incorrect_session = {}\n",
    "    for session_id, group in grouped_val:\n",
    "        \n",
    "        scores = group['score']\n",
    "        sorted_arg = np.flip(np.argsort(scores))\n",
    "\n",
    "        if group['label'].values[sorted_arg][0] != 1:\n",
    "            incorrect_session[session_id] = (sorted_arg.values, group['label'].values[sorted_arg])\n",
    "\n",
    "        rss.append( group['label'].values[sorted_arg])\n",
    "        rss_group[len(group)].append(group['label'].values[sorted_arg])\n",
    "\n",
    "    mrr = compute_mean_reciprocal_rank(rss)\n",
    "    mrr_group = {i:(len(rss_group[i]), compute_mean_reciprocal_rank(rss_group[i])) for i in range(1,26)}\n",
    "    # print(mrr_group)\n",
    "    pickle.dump( incorrect_session, open(f'../output/{model_name}_val_incorrect_order.p','wb'))\n",
    "\n",
    "    return mrr, mrr_group, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type='cuda'\n",
    "\n",
    "crit = configuration.loss()\n",
    "\n",
    "best_mrr = 0\n",
    "early_stopping = configuration.early_stopping\n",
    "not_improve_round = 0\n",
    "val_loader = data_gen.evaluate_data_valid()\n",
    "test_loader =data_gen.instance_a_test_loader()\n",
    "train_loader = data_gen.instance_a_train_loader()\n",
    "n_iter = 0\n",
    "stopped = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29it [00:07,  3.67it/s]                        \n",
      "/home/marci/anaconda3/envs/trivago/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/marci/anaconda3/envs/trivago/lib/python3.7/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "improve from 0 to 0.711111111111111\n",
      "BEST mrr 0.711111111111111\n"
     ]
    }
   ],
   "source": [
    "for i in range(configuration.num_epochs):\n",
    "    \n",
    "    net.train()\n",
    "    for batch_id, data in enumerate(tqdm(train_loader)):\n",
    "        optim.zero_grad()\n",
    "        n_iter += 1\n",
    "\n",
    "        item_ids = Variable(data[0]).to(device=device_type)\n",
    "        targets = Variable(data[1]).to(device=device_type)\n",
    "        past_interactions = Variable(data[2]).to(device=device_type)\n",
    "        \n",
    "        past_interaction_masks = (data[3])\n",
    "        \n",
    "        price_rank = Variable(data[4]).to(device=device_type)\n",
    "        city = Variable(data[5]).to(device=device_type)\n",
    "        last_item = Variable(data[6]).to(device=device_type)\n",
    "        impression_index = Variable(data[7]).to(device=device_type)\n",
    "        continuous_features = Variable(data[8]).to(device=device_type)\n",
    "        star = Variable(data[9]).to(device=device_type)\n",
    "        \n",
    "        past_interactions_sess = Variable(data[10]).to(device=device_type)\n",
    "        past_actions_sess = Variable(data[11]).to(device=device_type)\n",
    "        \n",
    "        # other_item_impressions = Variable(data[13]).to(device=device_type)\n",
    "        last_click_item = Variable(data[12]).to(device=device_type)\n",
    "        last_click_impression = Variable(data[13]).to(device=device_type)\n",
    "        last_interact_index = Variable(data[14]).to(device=device_type)\n",
    "        neighbor_prices = Variable(data[15]).to(device=device_type)\n",
    "        other_item_ids = Variable(data[16]).to(device=device_type)\n",
    "        city_platform = Variable(data[17]).to(device=device_type)\n",
    "        prediction = net(item_ids, past_interactions, past_interaction_masks, price_rank, city, last_item, impression_index, continuous_features, star, past_interactions_sess, past_actions_sess, last_click_item, last_click_impression, last_interact_index, neighbor_prices, other_item_ids, city_platform)\n",
    "        \n",
    "        loss = crit(prediction,targets)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    mrr, mrr_group, val_loss = evaluate_valid(val_loader, valid_data, net)\n",
    "    if mrr > best_mrr:\n",
    "        print(f\"improve from {best_mrr} to {mrr}\")\n",
    "        best_mrr = mrr\n",
    "        not_improve_round = 0\n",
    "        torch.save(net.state_dict(), weight_path)\n",
    "    else:\n",
    "        print(f\"didn't improve from {best_mrr} to {mrr}\")\n",
    "        not_improve_round += 1\n",
    "    if not_improve_round >= early_stopping:\n",
    "        break\n",
    "\n",
    "\n",
    "net.load_state_dict(torch.load(weight_path))    \n",
    "\n",
    "\n",
    "print(\"BEST mrr\", best_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pred df shape (68, 2)\n"
     ]
    }
   ],
   "source": [
    "if configuration.debug:\n",
    "    exit(0)\n",
    "       \n",
    "test_df = data_gen.test_data\n",
    "test_df['score'], _ = get_prediction(test_loader, net)\n",
    "\n",
    "with open(f'../output/{model_name}_test_score.p', 'wb') as f:\n",
    "    pickle.dump( test_df.loc[:,['score', 'session_id', 'step']],f, protocol=4)\n",
    "    \n",
    "grouped_test = test_df.groupby('session_id')\n",
    "predictions = []\n",
    "session_ids = []\n",
    "for session_id, group in grouped_test:\n",
    "    \n",
    "    scores = group['score']\n",
    "    sorted_arg = np.flip(np.argsort(scores))\n",
    "    sorted_item_ids = group['item_id'].values[sorted_arg]\n",
    "    sorted_item_ids = data_gen.cat_encoders['item_id'].reverse_transform(sorted_item_ids)\n",
    "    sorted_item_string = ' '.join([str(i) for i in sorted_item_ids])\n",
    "    predictions.append(sorted_item_string)\n",
    "    session_ids.append(session_id)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df['session_id'] = session_ids\n",
    "prediction_df['item_recommendations'] = predictions\n",
    "\n",
    "print(\"pred df shape\", prediction_df.shape)\n",
    "sub_df = pd.read_csv('../input/submission_popular.csv')\n",
    "sub_df.drop('item_recommendations', axis=1, inplace=True)\n",
    "sub_df = sub_df.merge(prediction_df, on=\"session_id\")\n",
    "# sub_df['item_recommendations'] = predictions\n",
    "\n",
    "sub_df.to_csv(f'../output/{model_name}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}